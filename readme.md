# 项目介绍
    本项目采用python编程语言，利用Pytorch机器学习框架，来进行模型的搭建以及训练。在项目中使用的数据集为CIFAR10，所使用的神经网络为ResNet残差网络。

# 模型结构
    ├── ResNet                     // 网络
    │   ├── BottleNeck
    |   |   ├── conv3*3            // 卷积层
    │   |   ├── bn                 // 批规范化
    │   |   ├── ReLU               // 激励函数
    │   |   ├── shortcut           // 与残差连接
    │   |       ├── conv3*3        // 用于downsample以及匹配通道数
    │   |       ├── bn             // 批规范化
    │   ├── fn                     // 全连接

    在项目采用的ResNet模型中，包含8个BottleNeck，每个BottleNeck两套（卷积 + 批规范化 + ReLU），原始的输入x又通过shortcut与其残差值相连接。其中 3 * 3 的卷积层都有一层padding，其stride可能为1或者2，用来匹配特征图的大小。在经过全部的BottleNeck后，又经过一层全连接层进行类别概率的输出。

# 数据集
    本项目所采用的数据集是CIFAR10数据集。从官网上下载好文件后，对训练数据以及测试数据分别进行读取。训练数据为（50000 * 32 * 32），测试数据为（100000 * 32 * 32），一共10个标签。对于训练数据，采用transform增强后转为Tensor，而测试数据直接转为Tensor。

# 模型训练
    一些训练中所用到的参数定义如下：
    ```
    batch_size : 128
    epochs : 200
    lr : 0.01
    ```
    其中学习率在每五轮的学习后都会降低为原来的0.9倍。

# 实验结果

- 总体正确率
![] (./Figure_1.png)
可以看到，训练集和测试集的正确率趋于收敛。最后测试集的正确率约为75%，训练集的正确率约为65%。测试集正确率比训练集正确率高的原因可能是数据划分不均匀导致的。而训练集正确率较低的原因猜测是网络较浅，参数变化不够。
- 改变batch_size
![] (./Figure_2.png)
当batch_size较小的时候，收敛速度会慢一些，反之就快一些。最后收敛后的正确率都差不多。
- 改变学习率
![] (./Figure_3.png)
可以看到，当学习率较大的时候，每个epoch的正确率反而会低。可能原因是学习率过大，导致权重变化过大，反而不利于损失的优化。
- 改变优化器
![] (./Figure_4.png)
在本实验中，SGD的收敛速度比Adam更快。这两种优化器最后的收敛正确率差不多。
    
